# ğŸ›¡ï¸ Sentinel AI â€” L7 Production AI Inference Platform

![Python](https://img.shields.io/badge/Python-3.11-blue)
![FastAPI](https://img.shields.io/badge/FastAPI-Production-green)
![CUDA](https://img.shields.io/badge/NVIDIA-CUDA-success)
![Docker](https://img.shields.io/badge/Docker-Enabled-blue)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-orange)
![Prometheus](https://img.shields.io/badge/Prometheus-Monitoring-red)
![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub_Actions-success)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

---

## ğŸ”¥ Overview

**Sentinel AI** is a **production-grade AI inference and observability platform** designed for **GPU-accelerated Large Language Model (LLM) workloads**.

Built using **FastAPI, NVIDIA CUDA, Llama 3, MLflow, Prometheus, Docker, Render, and n8n**, Sentinel AI demonstrates **L7-level system design** aligned with Big Tech and Big AI engineering standards.

This project emphasizes:
- Reliability
- Monitoring-first architecture
- Secure, scalable inference
- Cloud + GPU deployment readiness

---

## ğŸ§  System Architecture

![Sentinel AI Architecture](assets/sentinel_ai_system_architecture.png)

---

## âš™ï¸ Tech Stack

### Backend & AI
- **FastAPI** â€“ High-performance API layer
- **Python 3.11**
- **Meta Llama 3 (8B)** â€“ GPU-accelerated inference
- **PyTorch + Transformers**

### Infrastructure
- **Docker (CUDA-enabled)**
- **Render GPU deployment**
- **NVIDIA CUDA Runtime**

### Observability & Ops
- **MLflow** â€“ Experiment & inference tracking
- **Prometheus** â€“ Metrics & monitoring
- **n8n** â€“ AI workflow automation

### Security
- OAuth2 + JWT authentication
- Rate limiting (SlowAPI)

---

## ğŸš€ Quick Start

```bash
git clone https://github.com/Trojan3877/Sentinel-AI
cd Sentinel-AI

docker build -t sentinel-ai .
docker run --gpus all -p 8000:8000 sentinel-ai
http://localhost:8000


ğŸ“ˆ Production Features

âœ… GPU-backed LLM inference

âœ… FastAPI + async architecture

âœ… Auth & rate limiting

âœ… MLflow experiment tracking

âœ… Prometheus metrics

âœ… CI/CD ready

âœ… Cloud & GPU deployable

ğŸ§© Project Status

Engineering Level: L7 (Senior / Staff-level system design)

Readiness: Internship, New Grad, Research, MLOps, AI Engineer

Target Roles:

AI Engineer

ML Engineer

MLOps Engineer

Software Engineer (Backend / Platform)
ğŸ‘¤ Author

Corey Leath
Senior Undergraduate â€” Software Development (Web & Mobile)
Aspiring AI Engineer | Production ML Systems
https://github.com/Trojan3877
