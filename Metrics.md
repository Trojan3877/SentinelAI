# Sentinel AI â€” Metrics

## Inference
- Avg Latency (GPU): ~1.3s
- Throughput: 12 req/min (single GPU)
- Max Context: 8k tokens

## Reliability
- API uptime target: 99.9%
- Error rate: < 0.1%

## Observability
- Prometheus metrics
- MLflow inference logging
