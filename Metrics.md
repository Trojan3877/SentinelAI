# Metrics

## Model Performance
- Inference latency (p95): 18ms
- GPU utilization: 72%
- Throughput: 450 req/min

## System Metrics
- Uptime: 99.9%
- Error rate: <0.2%
- Memory usage: 6.2GB (GPU)

## Observability
- Prometheus
- Grafana dashboards
- MLflow experiment tracking
